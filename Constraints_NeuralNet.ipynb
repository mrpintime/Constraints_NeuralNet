{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyM/6Mlj1IyRMlaIEOpHVvMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrpintime/Constraints_NeuralNet/blob/main/Constraints_NeuralNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 7  \n"
      ],
      "metadata": {
        "id": "tAZ5NDO4Msj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approche 1  \n",
        "Several Conflict Matrix"
      ],
      "metadata": {
        "id": "0SLNJXfAKXKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "list_of_conflicts = []\n",
        "\n",
        "while len(list_of_conflicts) < 30:\n",
        "    pairs_list = set()\n",
        "    matrix = np.zeros((24, 24), dtype=int)\n",
        "\n",
        "    while matrix.sum() < 40:\n",
        "        num1 = np.random.choice(range(24))\n",
        "        num2 = np.random.choice(range(24))\n",
        "\n",
        "        if num1 == num2:\n",
        "            continue\n",
        "\n",
        "        pair = (num1, num2)\n",
        "        if pair in pairs_list:\n",
        "            continue\n",
        "\n",
        "        pairs_list.add(pair)\n",
        "        matrix[num1, num2] = 1\n",
        "\n",
        "    if not any(np.array_equal(matrix, conflict) for conflict in list_of_conflicts):\n",
        "        list_of_conflicts.append(matrix)"
      ],
      "metadata": {
        "id": "lLe8nwxLJzIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conflicts = np.array(list_of_conflicts)"
      ],
      "metadata": {
        "id": "fvYvl0ID6xVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conflicts.shape"
      ],
      "metadata": {
        "id": "MMMdGqWFcOSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_adjacent_mask(n_seats, seats_per_row, seats_per_col):\n",
        "    adjacent_mask = np.zeros((n_seats, n_seats))\n",
        "    for i in range(n_seats):\n",
        "        if i % seats_per_row != 0:\n",
        "            adjacent_mask[i, i-1] = 1\n",
        "        if i % seats_per_row != seats_per_row-1:\n",
        "            adjacent_mask[i, i+1] = 1\n",
        "        if i >= seats_per_row:\n",
        "            adjacent_mask[i, i-seats_per_row] = 1\n",
        "        if i < n_seats-seats_per_row:\n",
        "            adjacent_mask[i, i+seats_per_row] = 1\n",
        "    return adjacent_mask\n",
        "\n",
        "adjacent_mask = create_adjacent_mask(24,6,4)"
      ],
      "metadata": {
        "id": "CcVuuOSDgQSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adjacent_mask.shape"
      ],
      "metadata": {
        "id": "_RCXexBzAU9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow"
      ],
      "metadata": {
        "id": "isnIm152L3Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "adjacent_mask = create_adjacent_mask(24, 6, 4)\n",
        "\n",
        "def calculate_conflict(seating_arrangement, conflict_matrix):\n",
        "    ca_mul = tf.convert_to_tensor(conflict_matrix * adjacent_mask, tf.float64)\n",
        "    conflicts = tf.reduce_sum(tf.matmul(tf.cast(seating_arrangement, tf.float64), ca_mul))\n",
        "    return conflicts\n",
        "\n",
        "def custom_loss(predicted_seating_arrangement, conflicts_tensor):\n",
        "    alpha = 0.99\n",
        "    beta = 1 - alpha\n",
        "    kl  = tf.keras.losses.KLDivergence(reduction='sum')\n",
        "    batch_size = predicted_seating_arrangement.shape[0]\n",
        "\n",
        "    # Ensure the predicted seating arrangement is in float64\n",
        "    predicted_seating_arrangement = tf.cast(predicted_seating_arrangement, tf.float64)\n",
        "\n",
        "    # Calculate Conflict in produced seating arrangement\n",
        "    conflict = calculate_conflict(predicted_seating_arrangement, conflicts_tensor)\n",
        "    # Ensure each seat is assigned to only one person (columns should sum to 1) (Uniqueness)\n",
        "    probs = tf.reduce_sum(predicted_seating_arrangement, axis=1) / tf.constant(24, dtype=tf.float64)\n",
        "    one_like = tf.ones_like(probs, tf.float64) / tf.constant(24, dtype=tf.float64)\n",
        "    # Calculate KLDivergence\n",
        "    uniqueness = kl(one_like, probs)\n",
        "\n",
        "    total_loss =  0.8 * uniqueness + 0.2 * conflict\n",
        "\n",
        "    return total_loss / batch_size # Normalize\n",
        "\n",
        "conflicts_tensor = tf.convert_to_tensor(conflicts, tf.float64)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(conflicts_tensor.shape[1:]),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(80, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(24*24, activation='relu'),\n",
        "    tf.keras.layers.Reshape((24, 24)),\n",
        "    tf.keras.layers.Softmax(axis=2)  # Applying softmax along the last axis\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "for epoch in range(20):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predicted_seating_arrangement = model(conflicts_tensor, training=True)\n",
        "        loss = custom_loss(predicted_seating_arrangement, conflicts_tensor)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    print(f'Epoch: {epoch}, Loss: {loss.numpy()}')"
      ],
      "metadata": {
        "id": "-3jEOYY6bDiG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "for epoch in range(200):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predicted_seating_arrangement = model(conflicts_tensor, training=True)\n",
        "        loss = custom_loss(predicted_seating_arrangement, conflicts_tensor)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    print(f'Epoch: {epoch}, Loss: {loss.numpy()}')"
      ],
      "metadata": {
        "id": "kqBphfVynb23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(conflicts_tensor)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wP7bxcFbI2qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reshape(tf.argmax(out, 2)[0], (6,4))"
      ],
      "metadata": {
        "id": "6exhk5DgcdZz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(tf.argmax(out, 2)[0]).size"
      ],
      "metadata": {
        "id": "sP969BP5cYc1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xo = np.array([np.unique(i).size for i in tf.argmax(out, 2)])\n",
        "xo"
      ],
      "metadata": {
        "id": "QEr4oJZ6qyps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = tf.reduce_sum(out, axis=1) / tf.constant(10, dtype=tf.float32)\n",
        "one_like = tf.ones_like(probs, tf.float32) / tf.constant(10, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "8xUxunRJe8sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_like.shape"
      ],
      "metadata": {
        "id": "Hz1zFrO1fAim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kl = tf.keras.losses.KLDivergence(reduction='sum')\n",
        "kl(one_like, probs)"
      ],
      "metadata": {
        "id": "46-KJJGjfZPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch"
      ],
      "metadata": {
        "id": "ZkyqDVKwL5pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as op"
      ],
      "metadata": {
        "id": "URqq-PKpL68E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SeatingArr(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(SeatingArr, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dense_1 = nn.Linear(24*24, 80, dtype=torch.float64)\n",
        "        self.dense_2 = nn.Linear(80, 100, dtype=torch.float64)\n",
        "        self.dense_3 = nn.Linear(100, 24 * 24, dtype=torch.float64)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.dense_1(x))\n",
        "        x = F.relu(self.dense_2(x))\n",
        "        x = F.relu(self.dense_3(x))\n",
        "        x = x.view(-1,24,24)\n",
        "        x = F.softmax(x, dim=2)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "O04p1ZE6PsS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = SeatingArr()\n",
        "optim = op.Adam(params=net.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "SPbYGiQDTv4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_conflicts = torch.tensor(conflicts, dtype=torch.float64)\n",
        "loader = torch.utils.data.DataLoader(torch_conflicts, batch_size=64, pin_memory=True)\n",
        "examples = enumerate(loader)\n",
        "batch_idx, example_data = next(examples)"
      ],
      "metadata": {
        "id": "1aeJRUSSUkWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_idx, example_data.shape, loader.batch_size, loader.dataset.shape, len(loader.dataset), len(loader)"
      ],
      "metadata": {
        "id": "UAq9gapWVOzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_data.type()"
      ],
      "metadata": {
        "id": "AFH5gkdNY_PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adjacent_mask = create_adjacent_mask(n_seats=24, seats_per_row=6, seats_per_col=4)\n",
        "adjacent_mask_torch = torch.tensor(adjacent_mask, dtype=torch.float64)\n",
        "\n",
        "def calculate_conflict_torch(seating_arrangement, conflict_matrix):\n",
        "    ca_mul = conflict_matrix * adjacent_mask_torch\n",
        "    conflicts = torch.sum(torch.matmul(seating_arrangement.type(torch.float64), ca_mul))\n",
        "    return conflicts\n",
        "\n",
        "def custom_loss_torch(predicted_seating_arrangement, conflicts_tensor):\n",
        "    alpha = 0.99\n",
        "    beta = 1 - alpha\n",
        "    kl  = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    batch_size = predicted_seating_arrangement.shape[0]\n",
        "    # Ensure the predicted seating arrangement is in float64\n",
        "    predicted_seating_arrangement = predicted_seating_arrangement.type(torch.float64)\n",
        "\n",
        "    # Calculate Conflict in produced seating arrangement\n",
        "    conflict = calculate_conflict_torch(predicted_seating_arrangement, conflicts_tensor)\n",
        "\n",
        "    # Ensure each seat is assigned to only one person (columns should sum to 1) (Uniqueness)\n",
        "    probs = torch.sum(predicted_seating_arrangement, dim=1) / torch.tensor(24, requires_grad=False, dtype=torch.float64)\n",
        "    one_like = torch.ones_like(probs, dtype=torch.float64) / torch.tensor(24, requires_grad=False, dtype=torch.float64)\n",
        "    # Calculate KLDivergence\n",
        "    uniqueness = kl(torch.log(probs), one_like)\n",
        "    # Total Loss\n",
        "    total_loss =  alpha * uniqueness + beta * conflict\n",
        "\n",
        "    return total_loss / batch_size # Normalize"
      ],
      "metadata": {
        "id": "ptem726OVXAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model every 10 epochs\n",
        "interval = 10\n",
        "\n",
        "def Training(epoch):\n",
        "    # train\n",
        "    overal_loss = 0\n",
        "    net.train()\n",
        "    for batch_idx, conflict in enumerate(loader):\n",
        "        optim.zero_grad()\n",
        "        output = net(conflict)\n",
        "        loss = custom_loss_torch(output, conflict)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        overal_loss += loss.item()\n",
        "    if epoch % interval == 0:\n",
        "        print('Train Epoch: {} Loss: {:.6f}'.format(epoch, overal_loss))\n",
        "        # save state of model and optimizer\n",
        "        torch.save(net.state_dict(), '/content/model.pth')\n",
        "        torch.save(optim.state_dict(), '/content/optimizer.pth')\n"
      ],
      "metadata": {
        "id": "mkyWdiNUUGPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 800\n",
        "for i in range(n_epoch):\n",
        "     Training(i+1)"
      ],
      "metadata": {
        "id": "nG9lI7z3b44f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    output = net(torch_conflicts)\n",
        "    loss = custom_loss_torch(output, torch_conflicts)\n",
        "    loss_val = loss.item()\n",
        "    model_out_readable = torch.argmax(output, dim=2)"
      ],
      "metadata": {
        "id": "nC1DPugDckZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_val"
      ],
      "metadata": {
        "id": "SQQgnIWXfj1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_out_readable[0]"
      ],
      "metadata": {
        "id": "XoP1gUQLfr6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_out_readable[0].view(6,4)"
      ],
      "metadata": {
        "id": "qhAxHqF6ftTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xo = np.array([np.unique(i).size for i in model_out_readable])\n",
        "xo"
      ],
      "metadata": {
        "id": "fR-4W36S4aRO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}